{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš— Collisions in NY City ðŸ—½\n",
    "**Authors**: Carlos ArbonÃ©s & Benet RamiÃ³"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](../data/photo_cars_ny.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We acquired the dataset from the [Motor Vehicle Collisions](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95) source. Prior to obtaining it, we specifically filtered and downloaded the records corresponding to the periods of June to September in both 2018 and 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial dataset contains 115740 rows and 30 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the preprocessing process, we meticulously reviewed every column, focusing on aspects such as data types, the presence of null values, and potential clustering patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'Crash Date' column, we have maintained the data type as text, and it's important to note that **no null values** were found. The data within this column also appears to be in a **consistent format**. To enhance data organization and facilitate further analysis, we have **sorted** rows by 'Crash Date'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 'Crash Time' column, we've observed that **no null values** are present. Notably, we noticed specific hours, such as 00:00 and 13:00, a significant number of accidents occur. Exact hours, like 15:20 or 6:45, are more frequent than minutes, for instance, 19 or 23. This suggests that officers might commonly make **typographical errors** when recording minute values, which we have taken into account during the preprocessing process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Borough' column contains a limited set of distinct values, namely, **BRONX, BROOKLYN, MANHATTAN, QUEENS, STATEN ISLAND**, and blank. Notably, there are a significant number of records where the 'Borough' value is **blank**, with a total of **40,671** occurrences. We do not eliminate these rows, as they can be used for counting and other applications. We also explored the option of imputing values using the GeoPandas library; however, due to the high cost and the prevalence of missing values, it would take a considerable amount of time. Therefore, we have taken into account the existence of blank entries for later consideration in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've observed that there are 208 distinct zip codes within the dataset. It's important to note that a even though having too many zip codes, they can be extracted to the borough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude, Longitude and Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data preprocessing phase, we took several steps to enhance the quality and consistency of the 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "We first converted the data type of 'Latitude' and 'Longitude' to number. We also made the decision to remove the 'Location' column since the necessary information is now adequately represented in the 'Latitude' and 'Longitude' columns. It's important to highlight that there are a total of 7,667 blank values in these columns.\n",
    "\n",
    "During the data inspection, we identified atypical and impossible values, such as a longitude of -201. These outliers were associated with the location \"QUEENSBORO BRIDGE UPPER BROADWAY\", and after verifying the correct longitude, we adjusted these values to -73.954224. Similar outlier corrections were made for the \"NASSAU EXPRESSWAY\" location, where the previous value of -32 was corrected to -73.7813672, and for the \"WEST SHORE EXPRESSWAY\", where the previous value of -74.7 was corrected to -74.1864671. Finally, rows that had both 'Latitude' and 'Longitude' values equal to 0 were modified to contain blank text values, promoting uniformity and clarity in the dataset.\n",
    "\n",
    "These preprocessing actions have been taken to ensure that the 'Latitude' and 'Longitude' data are accurate, free from anomalies, and suitable for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ON STREET NAME, CROSS STREET NAME and OFF STREET NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of our data preprocessing, we have opted to remove the 'On Street Name,' 'Cross Street Name,' and 'Off Street Name' columns from the dataset. This decision is influenced by several key factors. Firstly, these columns contained a significant number of blank values, with 'On Street Name' having approximately 28,000 blanks, 'Cross Street Name' over 57,000 blanks, and 'Off Street Name' about 80,000 blanks. The prevalence of missing data in these columns significantly affected the overall data quality.\n",
    "\n",
    "Furthermore, the information contained within these columns was found to be redundant, and the extensive variety of street names made it challenging to derive meaningful insights or create compelling visualizations based on these columns. To fulfill the need for location-related information, we have chosen to rely on the 'Latitude' and 'Longitude' columns, which provide more structured and comprehensive geographic data. This not only reduces redundancy but also enhances data clarity and usability for our visualization project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INJURED AND KILLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have changed the datatype of all the injured and killed columns to number as well as changed the column names to shorter and more informative ones.\n",
    "The old column names and their corresponding new names are as follows:\n",
    "\n",
    "- NUMBER OF PERSONS INJURED -> TOTAL_INJURED\n",
    "- NUMBER OF PERSONS KILLED -> TOTAL_KILLED\n",
    "- NUMBER OF PEDASTRIANS INJURED -> PEDASTRIANS_INJURED\n",
    "- NUMBER OF PEDASTRIANS KILLED -> PEDASTRIANS_KILLED\n",
    "- NUMBER OF CYCLISTS INJURED -> CYCLISTS_INJURED\n",
    "- NUMBER OF CYCLISTS KILLED -> CYCLISTS_KILLED\n",
    "- NUMBER OF MOTORISTS INJURED -> MOTORISTS_INJURED\n",
    "- NUMBER OF MOTORISTS KILLED -> MOTORISTS_KILLED\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLISION_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have removed this column since it is not needed for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE TYPE CODE 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both 'VEHICLE TYPE CODE 1' and 'VEHICLE TYPE CODE 2,' a comprehensive data standardization process was undertaken. Initially, we applied clustering techniques using the Nearest Neighbor Method and Key Collision Method to harmonize and unify vehicle type names. These automated methods aided in resolving many inconsistencies caused by human errors.\n",
    "\n",
    "Recognizing that the automated clustering did not catch all errors, we conducted a meticulous manual review of vehicle type names. In cases where specific vehicles were inaccurately described, we updated their names. For instance, we found entries like 'GLP050VXEV,' which, upon internet research, was identified as a forklift model, so we modified it accordingly. Similar manual refinements were applied to various other vehicle types to improve accuracy and consistency.\n",
    "\n",
    "Additionally, we adopted a generalization approach to simplify overly specific vehicle types. For example, entities like 'FedEx,' 'UPS,' 'mail' and others were categorized under 'delivery' to reduce the number of distinct vehicle classes.\n",
    "\n",
    "To further enhance data consistency, vehicle types with fewer than ten collisions were grouped under the 'Others' category to streamline the dataset and reduce the number of unique names.\n",
    "\n",
    "It is remarkably that before these transformations, 'VEHICLE TYPE CODE 1' had 361 different names, and 'VEHICLE TYPE CODE 2' had 373 and, after, there are 42 and 44 respectivly. These preprocessing steps aimed to standardize and simplify the vehicle type data, making it more manageable and coherent for our analysis and visualization efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE TYPE CODE 3, 4 & 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that the majority of accidents typically involve two vehicles, the 'VEHICLE TYPE CODE 3,' 'VEHICLE TYPE CODE 4,' and 'VEHICLE TYPE CODE 5' columns contained a significant number of blank values. Specifically, 'VEHICLE TYPE CODE 3' had 107,095 blanks, 'VEHICLE TYPE CODE 4' had 113,658 blanks, and 'VEHICLE TYPE CODE 5' had 115,154 blanks. These observations indicate that the vast majority of records in these columns did not contain meaningful data.\n",
    "\n",
    "To streamline the dataset and focus on more relevant and informative columns, we have made the decision to remove these three columns. The absence of data in these columns, coupled with their limited relevance for our visualizations, makes their removal a practical and efficient choice in our data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTING_FACTOR_VEHICLE1, 2, 3, 4, & 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of null values in the CONTRIBUTING_FACTOR3, 4, 5 columns, we have decided to eliminate them as they will not be useful for our analysis. We have retained columns 1 and 2 in case we want to analyze the primary causes of accidents in New York at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the types of charts we want to create, we found it beneficial to add more attributes to the dataset, particularly those related to the date. In this case, we decided to combine the 'CRASH_DATE' and 'CRASH_TIME' columns into a single column containing the data in a format suitable for Altair. We created a new column named 'CRASH_DATETIME' in the format '%m/%d/%Y %H:%M'. We also added another column, 'DAY_WEEK,' that indicates the day of the week when the accident occurred (e.g., Monday, ...). Additionally, we introduced a column named 'TYPE_DAY' containing values 'Weekend' and 'Weekday' based on whether the accidents happened on the weekend or during the week, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = pd.read_csv(\"../data/preprocessed-collisions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions['CRASH_DATETIME'] = pd.to_datetime(collisions['CRASH_DATE'] + ' ' + collisions['CRASH_TIME'], format='%m/%d/%Y %H:%M')\n",
    "collisions = collisions.drop(columns=['CRASH_TIME'])\n",
    "collisions['DAY_WEEK'] = collisions['CRASH_DATETIME'].dt.day_name()\n",
    "collisions['TYPE_DAY'] = collisions['DAY_WEEK'].apply(lambda day: 'Weekend' if day in ['Saturday', 'Sunday'] else 'Weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the columns we need\n",
    "collisions = collisions[['CRASH_DATETIME', 'DAY_WEEK', 'TYPE_DAY', 'BOROUGH', 'ZIP_CODE', 'LATITUDE', 'LONGITUDE', '']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.to_csv(\"../data/preprocessed-collisions-final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the preprocessing, the dataset has 115740 rows and 20 columns\n"
     ]
    }
   ],
   "source": [
    "print(f'After the preprocessing, the dataset has {len(collisions)} rows and {len(collisions.columns)} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design and implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = pd.read_csv('../data/preprocessed-collisions-final.csv', dtype={'ZIP_CODE': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are accidents more frequent during weekdays or weekends? Is there any difference between before COVID-19 and after?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is crucial to differentiate between weekdays and weekends, as well as the periods preceding and following the onset of COVID (2018 and 2020). Our initial strategy revolves around structuring the data with the day of the week on the x-axis and consolidating the accident counts for each day. This approach enables us to discern notable variations between weekdays and weekends.\n",
    "\n",
    "For the comparative analysis of accident numbers before and after COVID, we suggest employing a paired bar chart. This graphical representation will utilize different colors for each period, facilitating a straightforward and visually impactful comparison between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_bar_chart = alt.Chart(collisions).mark_bar().encode(\n",
    "  x = alt.X('year:O', title = 'Type of day', axis=alt.Axis(title=None, labels=False, ticks=False)), \n",
    "  y = alt.Y('count:Q', title = 'Number of collisions', axis=alt.Axis(offset=6)),\n",
    "  color= alt.Color('year:O', scale = alt.Scale(scheme='tableau10')),\n",
    "  column = alt.Column('DAY_WEEK:N', title='Day of the Week', \n",
    "                      sort=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "                      header=alt.Header(titleOrient='bottom', labelOrient='bottom', labelPadding=4))\n",
    ").transform_calculate(\n",
    "  year = 'year(datum.CRASH_DATETIME)',\n",
    ").transform_aggregate(\n",
    "  count='count()',\n",
    "  groupby=['year', 'DAY_WEEK']\n",
    ")\n",
    "\n",
    "# paired_bar_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the previous chart that it allows differentiation between the years for the same day of the week, enabling a comparison before and after COVID. However, we've noticed that for comparing and analyzing whether there have been more accidents on weekdays or weekends, the chart is somewhat limited. Therefore, our next step is to add a slope chart to incorporate this information, which is not being well encoded at the moment.\n",
    "\n",
    "\n",
    "We also explored the option of standardizing the data by normalizing each value based on the corresponding count of occurrences on each day of the week, such as Mondays, Tuesdays, and so on. However, we believe that this would complicate the implementation. Instead, we will make the assumption that in the four months from June to September, from which we have extracted the data, there is a roughly equal distribution of days of the week. In other words, we assume that there are approximately the same number of Mondays as Tuesdays, Wednesdays, and so forth, which is more or less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_chart = alt.Chart(collisions).mark_line(point=True).encode(\n",
    "  x=alt.X('TYPE_DAY:O', title = 'Type of day'),\n",
    "  y=alt.Y('avg_collisions:Q', title = 'Average number of collisions'),\n",
    "  color=alt.Color('year:O', scale = alt.Scale(scheme='tableau10'), legend=alt.Legend(title='Year')),\n",
    ").transform_calculate(\n",
    "  year='year(datum.CRASH_DATETIME)'\n",
    ").transform_aggregate(\n",
    "  count='count()',\n",
    "  groupby=['year', 'DAY_WEEK', 'TYPE_DAY']\n",
    ").transform_aggregate(\n",
    "  avg_collisions = 'mean(count)',\n",
    "  groupby=['year', 'TYPE_DAY']\n",
    ")\n",
    "\n",
    "# (paired_bar_chart | slope_chart).properties(\n",
    "#      title='Number of collisions by day of the week and year'\n",
    "# ).configure_title(\n",
    "#   anchor='middle', offset=25, fontSize=18, fontStyle='normal', fontWeight='normal'\n",
    "# ).configure_view(\n",
    "#   stroke='transparent'\n",
    "# ).resolve_scale(\n",
    "#   y='shared'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This view, composed of juxtaposed charts, enables us to encode all the information we desire. The bar chart has been employed due to its linear representation of changes, making distinctions easily perceptible. Within each category (day of the week), values can be compared based on the year. While comparing across days of the week is more complex, it is less relevant in this case as our primary focus is not on inter-category comparisons. The bar chart makes it easy to identify specific data within the same category but is less suitable for comparisons between different categories.\n",
    "\n",
    "In any case, our focus is on comparing weekdays and weekends, and as mentioned previously, the slope chart is adept at capturing this comparison. We chose the slope chart because it is specifically crafted to encode two values, aligning seamlessly with our dataset. It serves the dual purpose of illustrating the increase or decrease of two data points over time. Its simplicity, paired with its high utility, enables swift and effective comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any type of vehicle more prone to participate in accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address this question, we will utilize the data from the 'VEHICLE_TYPE_CODE1' and 'VEHICLE_TYPE_CODE2' columns, which contain the names of the vehicles involved in accidents. In this instance, we will combine values from both columns and generate an auxiliary dataset called 'vehicle_type' that will include the vehicle name and the number of accidents it has been involved in, denoted as 'n_accidents'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48 different types of vehicles in the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>n_accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-Door</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambulance</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armored Truck</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beverage Truck</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bike</td>\n",
       "      <td>5543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     vehicle_type  n_accidents\n",
       "0          3-Door           50\n",
       "1       Ambulance          732\n",
       "2   Armored Truck           55\n",
       "3  Beverage Truck           55\n",
       "4            Bike         5543"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_type = pd.DataFrame({'vehicle_type': list(collisions['VEHICLE_TYPE_CODE1'].values) + list(collisions['VEHICLE_TYPE_CODE2'].values)})\n",
    "vehicle_type = vehicle_type.groupby('vehicle_type').size().reset_index(name='n_accidents')\n",
    "print(f'There are {len(vehicle_type)} different types of vehicles in the dataset')\n",
    "vehicle_type.head()                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the extensive variety of vehicles in the dataset, encoding all of them in a single chart becomes impractical. The next step is to select the top 10 vehicle types with the highest accident counts. While this number could be different, we have observed that with more than 10, the accident counts for each vehicle type become relatively small, hindering effective visualization. Therefore, we opt to focus on the top 10 vehicle types with the highest accident frequencies for clearer representation. The values for the remaining vehicles have been grouped under \"Others\". By consolidating the less frequent vehicle types into a category labeled \"Others,\" we streamline the visualization and prioritize clarity. This approach allows us to highlight the top 10 vehicle types with the highest accident frequencies, providing a more focused and interpretable representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most collisioned vehicles are: ['Sedan', 'SUV', 'Taxi', 'Pickup', 'Bike', 'Box truck', 'Bus', 'Truck', 'Motorcycle', 'Van']\n"
     ]
    }
   ],
   "source": [
    "most_collisioned = list(vehicle_type.sort_values(by='n_accidents', ascending=False).head(10)['vehicle_type'])\n",
    "vehicle_type['vehicle_type'] = vehicle_type['vehicle_type'].apply(lambda x: x if x in most_collisioned else 'Others')\n",
    "vehicle_type = vehicle_type.groupby('vehicle_type').sum('counts').reset_index()\n",
    "vehicle_type = vehicle_type.sort_values(by='n_accidents', ascending=False)\n",
    "print(f'The 10 most collisioned vehicles are: {most_collisioned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initial analysis aims to identify the most frequently involved vehicles in accidents. Our first choice for representation is using a bar chart. On the x-axis, we will have the total number of accidents for each vehicle, and on the y-axis, we will list the vehicle names. We adopt this approach to ensure clear legibility of the vehicle names, facilitating effective comparisons. Additionally, we find it beneficial to include a vertical line in red, indicating the average value of accidents involved. This addition allows for easy comparison of vehicles that surpass or fall below this average. Additionally, we will arrange the bars in descending order based on their values, facilitating easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart = alt.Chart(vehicle_type).mark_bar().encode(\n",
    "    x=alt.X('n_accidents:Q', title='Number of collisions', scale=alt.Scale(domain=(0, 1e5 + 1))),\n",
    "    y=alt.Y('vehicle_type:N', \n",
    "            sort=list(vehicle_type.loc[vehicle_type['vehicle_type'] != 'Others', 'vehicle_type']) + ['Others'], \n",
    "            title='Vehicle Type'),\n",
    "    color=alt.condition(\n",
    "            alt.datum.vehicle_type == 'Others', \n",
    "            alt.value('grey'),\n",
    "            alt.value('steelblue')\n",
    "        )\n",
    ")\n",
    "    \n",
    "mean_line = alt.Chart(vehicle_type).mark_rule(color='red', strokeWidth=1.5).encode(\n",
    "        x = alt.X('mean(n_accidents):Q')\n",
    ")\n",
    "\n",
    "# (bar_chart + mean_line).properties(\n",
    "#         title='Number of collisions by vehicle type'\n",
    "# ).configure_title(\n",
    "#         anchor='middle', fontSize=16, fontStyle='normal', fontWeight='normal', offset=20\n",
    "# ).properties(\n",
    "#         width=500, \n",
    "#         height=300\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The chart appears quite accurate, but we have decided to include the values of the bars to facilitate comparison. In its current form, it is evident which values are larger or smaller than others, but the exact values cannot be precisely determined. Therefore, even though adding the accident count values may seem redundant, we believe it aids in performing the tasks more effectively.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_accidents_text = alt.Chart(vehicle_type).mark_text(align='left', dx=2, color='black', size=10).encode(\n",
    "        x=alt.X('n_accidents:Q'),\n",
    "        y=alt.Y('vehicle_type:N', \n",
    "            sort=list(vehicle_type.loc[vehicle_type['vehicle_type'] != 'Others', 'vehicle_type']) + ['Others']),\n",
    "        text='n_accidents:Q'\n",
    ")\n",
    "\n",
    "# (bar_chart + mean_line + n_accidents_text).properties(\n",
    "#         title='Number of collisions by vehicle type'\n",
    "# ).configure_title(\n",
    "#         anchor='middle', fontSize=16, fontStyle='normal', fontWeight='normal', offset=20\n",
    "# ).properties(\n",
    "#         width=500, \n",
    "#         height=300\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with this chart is that it displays the number of accidents for each vehicle type during the given time period. However, it doesn't provide information about whether a particular vehicle is more prone to accidents than another, as we lack data on the total number of each type of vehicle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At what time of the day are accidents more common?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the temporal patterns of accidents throughout the day, we will employ a line chart. The x-axis will represent hours, with the y-axis indicating the corresponding number of accidents. Opting for a line chart enables a clear depiction of how accident frequencies evolve over time. We will differentiate the data by year, using distinct colors for 2018 and 2020, providing a comparative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_count = alt.Chart(collisions).mark_line(strokeWidth=2, point=True).encode(\n",
    "    alt.X('hours(CRASH_DATETIME):O', title='Time of Day'),\n",
    "    alt.Y('count():Q', title='Number of Collisions'),\n",
    "    color= alt.Color('year(CRASH_DATETIME):O', scale = alt.Scale(scheme='tableau10'))\n",
    ")\n",
    "\n",
    "# line_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These type of visualization seems to work, dispite that it can be improved. We see that in the y-axis we have the total number of collisions by hour. These encoding make it challenging to intuitively grasp the frequency of accidents for each hour each day. To address this, we will refine the visualization by encoding the average number of accidents of each day, accompanied by an error bar indicating the standard deviation so that we can assess the variance of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions2 = collisions.copy()\n",
    "collisions2['CRASH_DATETIME'] = pd.to_datetime(collisions2['CRASH_DATETIME'])\n",
    "# Extract year and hours from CRASH_DATETIME\n",
    "collisions2['year'] = collisions2['CRASH_DATETIME'].dt.year\n",
    "collisions2['hours'] = collisions2['CRASH_DATETIME'].dt.hour\n",
    "\n",
    "collisions2 = collisions2.groupby(['year', 'hours', 'CRASH_DATE']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate average and confidence interval\n",
    "average_ci = collisions2.groupby(['year', 'hours']).agg(\n",
    "    avg=('count', 'mean'),\n",
    "    ci_lower=('count', lambda x: np.percentile(x, 5)),\n",
    "    ci_upper=('count', lambda x: np.percentile(x, 95))\n",
    ").reset_index()\n",
    "\n",
    "# Line chart for average with confidence intervals\n",
    "line_chart = alt.Chart(average_ci).mark_line().encode(\n",
    "    x=alt.X('hours:Q', title='Time of day'),\n",
    "    y=alt.Y('avg:Q', title='Average number of collisions'),\n",
    "    color=alt.Color('year:N', scale=alt.Scale(scheme='tableau10'))\n",
    ")\n",
    "\n",
    "error_bars = alt.Chart(average_ci).mark_errorband().encode(\n",
    "    x=alt.X('hours:Q'),\n",
    "    y=alt.Y('ci_lower:Q', title='Number of collisions'),\n",
    "    y2=alt.Y2('ci_upper:Q'),\n",
    "    color=alt.Color('year:N', scale=alt.Scale(scheme='tableau10'))\n",
    ")\n",
    "\n",
    "# (line_chart + error_bars).properties(width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_average = alt.Chart(collisions).mark_line(strokeWidth=2, point=True).encode(\n",
    "    x = alt.X('hours:Q', title='Time of day'),\n",
    "    y = alt.Y('avg:Q', title='Average number of collisions'),\n",
    "    color = alt.Color('year:O', scale = alt.Scale(scheme='tableau10'))\n",
    ").transform_calculate(\n",
    "  year = 'year(datum.CRASH_DATETIME)',\n",
    "  hours = 'hours(datum.CRASH_DATETIME)'\n",
    ").transform_aggregate(\n",
    "   count='count()',\n",
    "   groupby=['year', 'hours', 'CRASH_DATE']\n",
    ").transform_aggregate(\n",
    "    avg = 'mean(count)',\n",
    "    groupby=['year', 'hours']\n",
    ")\n",
    "\n",
    "error_bar = alt.Chart(collisions).mark_errorbar(ticks=True).encode(\n",
    "    x=alt.X('hours:Q'),\n",
    "    y=alt.Y('count:Q',axis=alt.Axis(title=None), scale=alt.Scale(zero=False)),\n",
    "    color = alt.Color('year:O', scale = alt.Scale(scheme='tableau10'))\n",
    ").transform_calculate(\n",
    "  year = 'year(datum.CRASH_DATETIME)',\n",
    "  hours = 'hours(datum.CRASH_DATETIME)'\n",
    ").transform_aggregate(\n",
    "   count='count()',\n",
    "   groupby=['year', 'hours', 'CRASH_DATE']\n",
    ")\n",
    "\n",
    "# (line_average + error_bar).properties(width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon analyzing the hourly collisions, a clear trend emerges: higher collision rates during the day and lower rates during the night. This pattern aligns with the increased presence of cars on the road during daylight hours and decreased activity during nighttime. Further we can distinguish different patterns between morning, afternoon, and evening periods. Mornings exhibit fewer collisions, likely attributed to work-related activities, whereas afternoons register higher incidents, potentially linked to leisure activities and transporting children to extracurricular activities. Evenings witness a decline in collisions as people conclude their activities and return home.\n",
    "\n",
    "We can further enhance our chart by introducing an additional variable to glean more insights. One pivotal factor of high importance is the total number of deaths caused by the accidents. It's crucial not only to identify peak collision times throughout the day but also to comprehend the magnitude of the human cost associated with these incidents. These variable will be encoded through the line thickness, with thicker lines indicating a higher number of deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_deaths_line = alt.Chart(collisions).mark_trail().encode(\n",
    "    x = alt.X('hours:Q', title='Time of day'),\n",
    "    y = alt.Y('avg_collisions:Q', title='Average number of collisions'),\n",
    "    color = alt.Color('year:O', scale = alt.Scale(scheme='tableau10'), title='Year'),\n",
    "    size = alt.Size('avg_killed:Q', title='Average deaths')\n",
    ").transform_calculate(\n",
    "  year = 'year(datum.CRASH_DATETIME)',\n",
    "  hours = 'hours(datum.CRASH_DATETIME)'\n",
    ").transform_aggregate(\n",
    "  count_collisions='count()',\n",
    "  count_killed='sum(TOTAL_KILLED)',\n",
    "  groupby=['year', 'hours', 'CRASH_DATE']\n",
    ").transform_aggregate(\n",
    "  avg_collisions='mean(count_collisions)',\n",
    "  avg_killed='mean(count_killed)',\n",
    "  groupby=['year', 'hours']\n",
    ")\n",
    "\n",
    "# (avg_deaths_line + error_bars).properties(\n",
    "#     title='Average collisions and deaths over time',\n",
    "#     width=600,\n",
    "#     height=400\n",
    "#     ).configure_title(\n",
    "#       anchor='middle', offset=25, fontSize=18, fontStyle='normal', fontWeight='normal'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally achieved the final version of the graph. This visualization facilitates the identification of peak accident times. While the period with the highest collision frequency occurs around 16:00, instances of more severe outcomes, particularly deaths, are notable at 20:00 and 04:00 in 2018, and between 19:00 and 00:00, as well as at 04:00 in 2020. The deaths in the late night coincide with the times when people are returning home after socializing, often under the influence of alcohol, which make the accidents more dangerous.\n",
    "\n",
    "This visualization provides a clear depiction of the temporal patterns of accidents throughout the day which facilitates to identify what time of the day are accidents more common. However, the error bars and the line thickness make the visualization a bit cluttered and difficult to read. Dispite that we believe that the information they transmit is important enough to keep them in the visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*At what time of the day are accidents more common?*\n",
    "\n",
    "In chart C3 you can see a line chart with the average accidents per hour along the different years. We use a different color for each year and line thickness to encode the killed people. You can see that the accidents are more common during the afternoon, having the peak at 16:00, and the killed people are more common during the evening and late night."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any areas with a larger number of accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a smaller dataset named 'geo_collisions' containing only the columns used for analysis. Additionally, we drop all rows with NaN values to ensure data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_collisions = collisions[['LATITUDE', 'LONGITUDE', 'ZIP_CODE', 'BOROUGH']]\n",
    "geo_collisions = geo_collisions.dropna()\n",
    "geo_collisions['ZIP_CODE'] = geo_collisions['ZIP_CODE'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_city_map = alt.topo_feature('../data/ny_city_map.geojson', '')\n",
    "ny_city = alt.Chart(ny_city_map).mark_geoshape(\n",
    "    fill='lightgray',  \n",
    "    stroke='white',    \n",
    "    strokeWidth=1.5    \n",
    ")                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial idea is to create a point map where each accident is marked as a point on the New York map. This way, we aim to visualize which areas have more points and, consequently, more accidents. Additionally, we have considered that it would be helpful to have a reference for the number of accidents in each borough to scale the visualization. We will also reduce the opacity of the points to better distinguish those that are close together. We should use a categorical color palette since there is no specific order, and it should allow for clear differentiation between the various neighborhoods. Furthermore, we won't include redundant neighborhood information in the bar chart, as it is already encoded with color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_map = alt.Chart(geo_collisions).mark_circle(size=1, opacity=0.7).encode(\n",
    "    latitude='LATITUDE:Q',\n",
    "    longitude='LONGITUDE:Q',\n",
    "    color = alt.Color('BOROUGH:N', \n",
    "                      scale=alt.Scale(scheme='tableau10'))\n",
    ")\n",
    "\n",
    "bar_chart_map = alt.Chart(geo_collisions).mark_bar().encode(\n",
    "    alt.X('BOROUGH:N', title='Borough', axis=alt.Axis(title=None, labels=False, ticks=False)),\n",
    "    alt.Y('count():Q', title='Number of Accidents'),\n",
    "    color = alt.Color('BOROUGH:N', \n",
    "                      scale=alt.Scale(scheme='tableau10'),)\n",
    ")\n",
    "    \n",
    "# ((ny_city + point_map).properties(\n",
    "#     width=380,\n",
    "#     height=380\n",
    "# ) | bar_chart_map).properties(\n",
    "#     title = alt.TitleParams(text='Number of collisions by borough', \n",
    "#                             fontSize=18, \n",
    "#                             fontStyle='normal',\n",
    "#                             fontWeight='normal',\n",
    "#                             subtitle='', \n",
    "#                             offset=35)\n",
    "# ).configure_title(\n",
    "#     anchor='middle'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that the point map does not efficiently differentiate areas with more accidents. Due to the high volume of points, they overlap, creating regions of solid color that are challenging to interpret. Therefore, the next step will be to try a choropleth map, which differentiates by PostalCode and encodes the number of accidents in each area with color. One issue we encounter is that larger map regions will generally have more accidents, making it an unfair comparison. To address this, we have decided to normalize the number of accidents in a specific area by the area it occupies. Instead of encoding the raw number of accidents, we will encode the number of accidents per square kilometer to facilitate meaningful comparisons. We will use a Sequential Single-Hue palette for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../data/ny_city_map.geojson')\n",
    "gdf = gdf[['postalCode', 'Shape_Area', 'geometry']]\n",
    "area_gdf = gdf.to_crs(epsg=6933) # the length unit is now 'meter'\n",
    "gdf['Shape_Area'] = area_gdf.area.values / 1e6 # set the area units to sq Km.\n",
    "# gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge with the collisions dataset to obtain the count of accidents for each postal code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_collisions = gdf.merge(geo_collisions.groupby('ZIP_CODE').size().reset_index(name='n_accidents').rename(columns={'ZIP_CODE': 'postalCode'}), \n",
    "                           on='postalCode', \n",
    "                           how='left')\n",
    "# gdf_collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_collisions['n_accidents_per_km2'] = gdf_collisions['n_accidents']/gdf_collisions['Shape_Area']\n",
    "gdf_collisions['log_n_accidents_per_km2'] = gdf_collisions['n_accidents_per_km2'].apply(lambda x: np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postalCode</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>geometry</th>\n",
       "      <th>n_accidents</th>\n",
       "      <th>n_accidents_per_km2</th>\n",
       "      <th>log_n_accidents_per_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11372</td>\n",
       "      <td>1.875393</td>\n",
       "      <td>POLYGON ((-73.86942 40.74916, -73.89507 40.746...</td>\n",
       "      <td>657.0</td>\n",
       "      <td>350.326589</td>\n",
       "      <td>5.858866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11004</td>\n",
       "      <td>2.102007</td>\n",
       "      <td>POLYGON ((-73.71068 40.75004, -73.70869 40.748...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>77.544949</td>\n",
       "      <td>4.350858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11040</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>POLYGON ((-73.70098 40.73890, -73.70309 40.744...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>42.971107</td>\n",
       "      <td>3.760528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11426</td>\n",
       "      <td>4.588542</td>\n",
       "      <td>POLYGON ((-73.72270 40.75373, -73.72251 40.753...</td>\n",
       "      <td>151.0</td>\n",
       "      <td>32.908059</td>\n",
       "      <td>3.493718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11365</td>\n",
       "      <td>6.450179</td>\n",
       "      <td>POLYGON ((-73.81089 40.72717, -73.81116 40.728...</td>\n",
       "      <td>222.0</td>\n",
       "      <td>34.417651</td>\n",
       "      <td>3.538570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  postalCode  Shape_Area                                           geometry   \n",
       "0      11372    1.875393  POLYGON ((-73.86942 40.74916, -73.89507 40.746...  \\\n",
       "1      11004    2.102007  POLYGON ((-73.71068 40.75004, -73.70869 40.748...   \n",
       "2      11040    0.581786  POLYGON ((-73.70098 40.73890, -73.70309 40.744...   \n",
       "3      11426    4.588542  POLYGON ((-73.72270 40.75373, -73.72251 40.753...   \n",
       "4      11365    6.450179  POLYGON ((-73.81089 40.72717, -73.81116 40.728...   \n",
       "\n",
       "   n_accidents  n_accidents_per_km2  log_n_accidents_per_km2  \n",
       "0        657.0           350.326589                 5.858866  \n",
       "1        163.0            77.544949                 4.350858  \n",
       "2         25.0            42.971107                 3.760528  \n",
       "3        151.0            32.908059                 3.493718  \n",
       "4        222.0            34.417651                 3.538570  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "choropleth_map = alt.Chart(gdf_collisions).mark_geoshape().encode(\n",
    "    alt.Color('n_accidents_per_km2:Q',\n",
    "              title='Number of accidents per kmÂ²', \n",
    "              scale=alt.Scale(scheme='lighttealblue', domain=(0, 600)))\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "borough_names = alt.Chart(geo_collisions).mark_text(fontWeight='bold', fontSize=11, color='black').encode(\n",
    "    latitude='mean_lat:Q',\n",
    "    longitude='mean_long:Q',\n",
    "    text='BOROUGH:N',\n",
    ").transform_aggregate(\n",
    "    mean_lat='mean(LATITUDE)',\n",
    "    mean_long='mean(LONGITUDE)',\n",
    "    groupby=['BOROUGH']\n",
    ")\n",
    "\n",
    "# (choropleth_map + borough_names).properties(\n",
    "#      title='Number of Collisions by Postal Code'\n",
    "# ).configure_title(\n",
    "#         anchor='middle', fontSize=16, fontStyle='normal', fontWeight='normal', offset=20\n",
    "# ).configure_legend(\n",
    "#     strokeColor='gray',\n",
    "#     fillColor='#EEEEEE',\n",
    "#     padding=10,\n",
    "#     cornerRadius=10,\n",
    "#     orient='top-left',\n",
    "#     gradientLength=165\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choropleth map provides a clear visualization of areas (by postal code) with higher accident rates per square kilometer. We positioned the legend in the top-left corner to optimize visualization space. Additionally, we adjusted the color domain to highlight differences between areas. Specifically, values above a certain threshold are assigned the same color to enhance clarity.\n",
    "\n",
    "While the choropleth map allows for comparisons between postal code areas, we recognize the importance of effective comparisons between boroughs. To address this, we've introduced a bar chart to encode information on the number of accidents per square kilometer for each borough. This enables us to assess whether certain boroughs have significantly higher accident rates than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>n_accidents</th>\n",
       "      <th>n_accidents_per_sq_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>12426</td>\n",
       "      <td>113.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>24365</td>\n",
       "      <td>135.587090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>13159</td>\n",
       "      <td>223.792517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>19950</td>\n",
       "      <td>70.870337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>2786</td>\n",
       "      <td>18.710544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BOROUGH  n_accidents  n_accidents_per_sq_km\n",
       "0          BRONX        12426             113.687100\n",
       "1       BROOKLYN        24365             135.587090\n",
       "2      MANHATTAN        13159             223.792517\n",
       "3         QUEENS        19950              70.870337\n",
       "4  STATEN ISLAND         2786              18.710544"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area = {'BRONX': 109.3, 'BROOKLYN': 179.7, 'MANHATTAN': 58.8, 'QUEENS': 281.5, 'STATEN ISLAND': 148.9} # sq km of each borough\n",
    "\n",
    "accidents_per_borough = geo_collisions.groupby('BOROUGH').size().reset_index(name='n_accidents')\n",
    "accidents_per_borough['n_accidents_per_sq_km'] = accidents_per_borough.apply(\n",
    "    lambda x:  x['n_accidents'] / area[x['BOROUGH']],\n",
    "    axis=1\n",
    ")\n",
    "accidents_per_borough.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart_map2 = alt.Chart(accidents_per_borough).mark_bar().encode(\n",
    "    alt.X('BOROUGH:N', title='Borough', sort=alt.EncodingSortField(field=\"n_accidents_per_sq_km\", op=\"sum\", order='descending')),\n",
    "    alt.Y('n_accidents_per_sq_km:Q', title='Number of Accidents per kmÂ²'),\n",
    ")\n",
    "\n",
    "# alt.hconcat(\n",
    "#     choropleth_map + borough_names,\n",
    "#     bar_chart_map2\n",
    "# ).properties(\n",
    "#     title='Number of Collisions by Postal Code and Borough'\n",
    "# ).configure_title(\n",
    "#     anchor='middle', fontSize=16, fontStyle='normal', fontWeight='normal', offset=20\n",
    "# ).configure_legend(\n",
    "#     strokeColor='gray',\n",
    "#     fillColor='#EEEEEE',\n",
    "#     padding=10,\n",
    "#     cornerRadius=10,\n",
    "#     orient='top-left',\n",
    "#     gradientLength=165\n",
    "# ).configure_axis(\n",
    "#     labelFontSize=10,\n",
    "#     titleFontSize=12, \n",
    "#     labelFontStyle='normal',\n",
    "#     titleFontStyle='normal', \n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a correlation between weather conditions and accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting to create visualizations it is necessary to choose the attributes of the 'weather.csv' dataset. Furthermore, since we have one row per day in the weather dataset, we need to group the number of collisions per day in order to merge the two datasets appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>precip</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>humidity</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>conditions</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.28200</td>\n",
       "      <td>12.6</td>\n",
       "      <td>86.8</td>\n",
       "      <td>65.9</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.34600</td>\n",
       "      <td>22.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.92900</td>\n",
       "      <td>24.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>92.7</td>\n",
       "      <td>Rain, Overcast</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.91978</td>\n",
       "      <td>16.7</td>\n",
       "      <td>76.6</td>\n",
       "      <td>71.6</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>60.7</td>\n",
       "      <td>35.7</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  temp   precip  windspeed  humidity  cloudcover   \n",
       "0 2018-06-01  21.6  0.28200       12.6      86.8        65.9  \\\n",
       "1 2018-06-02  25.1  0.34600       22.3      74.0        35.4   \n",
       "2 2018-06-03  17.0  2.92900       24.1      75.0        92.7   \n",
       "3 2018-06-04  16.8  3.91978       16.7      76.6        71.6   \n",
       "4 2018-06-05  19.8  0.00000       25.9      60.7        35.7   \n",
       "\n",
       "               conditions  visibility  \n",
       "0  Rain, Partially cloudy        11.3  \n",
       "1  Rain, Partially cloudy        15.8  \n",
       "2          Rain, Overcast        15.6  \n",
       "3  Rain, Partially cloudy        15.4  \n",
       "4        Partially cloudy        16.0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_original = pd.read_csv(\"../data/weather.csv\")\n",
    "weather = weather_original[['datetime', 'temp', 'precip', 'windspeed', \n",
    "                            'humidity', 'cloudcover', 'conditions', 'visibility']]\n",
    "weather['datetime'] = pd.to_datetime(weather['datetime'])\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>collisions</th>\n",
       "      <th>temp</th>\n",
       "      <th>precip</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>humidity</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>conditions</th>\n",
       "      <th>visibility</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>751</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.28200</td>\n",
       "      <td>12.6</td>\n",
       "      <td>86.8</td>\n",
       "      <td>65.9</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>11.3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>622</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.34600</td>\n",
       "      <td>22.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>15.8</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>525</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.92900</td>\n",
       "      <td>24.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>92.7</td>\n",
       "      <td>Rain, Overcast</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>698</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.91978</td>\n",
       "      <td>16.7</td>\n",
       "      <td>76.6</td>\n",
       "      <td>71.6</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "      <td>15.4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>688</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>60.7</td>\n",
       "      <td>35.7</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  collisions  temp   precip  windspeed  humidity  cloudcover   \n",
       "0 2018-06-01         751  21.6  0.28200       12.6      86.8        65.9  \\\n",
       "1 2018-06-02         622  25.1  0.34600       22.3      74.0        35.4   \n",
       "2 2018-06-03         525  17.0  2.92900       24.1      75.0        92.7   \n",
       "3 2018-06-04         698  16.8  3.91978       16.7      76.6        71.6   \n",
       "4 2018-06-05         688  19.8  0.00000       25.9      60.7        35.7   \n",
       "\n",
       "               conditions  visibility  year  \n",
       "0  Rain, Partially cloudy        11.3  2018  \n",
       "1  Rain, Partially cloudy        15.8  2018  \n",
       "2          Rain, Overcast        15.6  2018  \n",
       "3  Rain, Partially cloudy        15.4  2018  \n",
       "4        Partially cloudy        16.0  2018  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_weather = pd.DataFrame({'datetime': collisions[\"CRASH_DATE\"]})\n",
    "coll_weather['datetime'] = pd.to_datetime(coll_weather['datetime'])\n",
    "coll_weather = coll_weather.groupby(['datetime']).size().reset_index(name='collisions')\n",
    "coll_weather = pd.merge(coll_weather, weather, on='datetime')\n",
    "coll_weather['year'] = coll_weather['datetime'].dt.year\n",
    "coll_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create two more datasets, one for each year because we will use these two datasets separately in some of the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_weather['conditions'] = coll_weather['conditions'].apply(lambda x: 'Rain, Overcast' if x=='Overcast' else x)\n",
    "\n",
    "coll_weather_2018 = coll_weather[coll_weather['year']==2018]\n",
    "coll_weather_2020 = coll_weather[coll_weather['year']==2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to create graphs to see if there is any correlation between weather condiditon and accidents. We will first try a parallel bar chart, we have choosen the variables that we considered that might be more related to the number of collisions. We will also differentiate the data by year, using distinct colors for 2018 and 2020, providing a comparative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sort_order = [ 'collisions', 'visibility', 'windspeed', 'temp', 'humidity', 'cloudcover']\n",
    "\n",
    "# alt.Chart(coll_weather, width=500).transform_window(\n",
    "#     index='count()'\n",
    "# ).transform_fold(\n",
    "#     ['temp', 'precip', 'windspeed', 'humidity', 'cloudcover', 'visibility', 'collisions']\n",
    "# ).mark_line().encode(\n",
    "#     x=alt.X('key:N', sort=custom_sort_order),\n",
    "#     y='value:Q',\n",
    "#     color='year:N',\n",
    "#     detail='index:N',\n",
    "#     opacity=alt.value(0.5)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first problem we see is that each variable has a different range of values so we will normalize the data to be able to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(coll_weather).transform_window(\n",
    "#     index='count()'\n",
    "# ).transform_fold(\n",
    "#     ['temp', 'windspeed', 'collisions', 'humidity', 'cloudcover', 'visibility']\n",
    "# ).transform_joinaggregate(\n",
    "#      min='min(value)',\n",
    "#      max='max(value)',\n",
    "#      groupby=['key']\n",
    "# ).transform_calculate(\n",
    "#     minmax_value=(alt.datum.value-alt.datum.min)/(alt.datum.max-alt.datum.min),\n",
    "#     mid=(alt.datum.min+alt.datum.max)/2\n",
    "# ).mark_line().encode(\n",
    "#     x=alt.X('key:N', sort=custom_sort_order),\n",
    "#     y='minmax_value:Q',\n",
    "#     color='year:N',\n",
    "#     detail='index:N',\n",
    "#     opacity=alt.value(0.5)\n",
    "# ).properties(width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite normalizing the data, the visualization is not clear enough to see if there is any correlation between the variables and the number of collisions. (we have trided different order of variables but nothing comes up). Maybe it is because since there is a lot of difference between the number of collisions in 2018 and 2020 we do not see trends. Our next graph will be a juxtaposition of two parallel coordinates charts, one for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart for coll_weather_2018\n",
    "chart_2018 = alt.Chart(coll_weather_2018).transform_window(\n",
    "    index='count()'\n",
    ").transform_fold(\n",
    "    ['temp', 'windspeed', 'collisions', 'humidity', 'cloudcover', 'visibility']\n",
    ").transform_joinaggregate(\n",
    "     min='min(value)',\n",
    "     max='max(value)',\n",
    "     groupby=['key']\n",
    ").transform_calculate(\n",
    "    minmax_value=(alt.datum.value-alt.datum.min)/(alt.datum.max-alt.datum.min),\n",
    "    mid=(alt.datum.min+alt.datum.max)/2\n",
    ").mark_line().encode(\n",
    "    x=alt.X('key:N', sort=custom_sort_order),\n",
    "    y='minmax_value:Q',\n",
    "    color=alt.value('steelblue'),\n",
    "    detail='index:N',\n",
    "    opacity=alt.value(0.5)\n",
    ").properties(width=500, title='2018')\n",
    "\n",
    "# Chart for coll_weather_2020\n",
    "chart_2020 = alt.Chart(coll_weather_2020).transform_window(\n",
    "    index='count()'\n",
    ").transform_fold(\n",
    "    ['temp', 'windspeed', 'collisions', 'humidity', 'cloudcover', 'visibility']\n",
    ").transform_joinaggregate(\n",
    "     min='min(value)',\n",
    "     max='max(value)',\n",
    "     groupby=['key']\n",
    ").transform_calculate(\n",
    "    minmax_value=(alt.datum.value-alt.datum.min)/(alt.datum.max-alt.datum.min),\n",
    "    mid=(alt.datum.min+alt.datum.max)/2\n",
    ").mark_line().encode(\n",
    "    x=alt.X('key:N', sort=custom_sort_order),\n",
    "    y='minmax_value:Q',\n",
    "    color=alt.value('#ff7f0e'),\n",
    "    detail='index:N',\n",
    "    opacity=alt.value(0.5)\n",
    ").properties(width=500, title='2020')\n",
    "\n",
    "# combined_chart = alt.hconcat(chart_2018, chart_2020)\n",
    "# combined_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were we may see som correlation with low visibility and high number of collisions, however, sine there are very few examples of low visibility compared to the ones with high visibility, we cannot conclude anything.\n",
    "\n",
    "So, our we will try to approach the problem in a different type of visualization. We will use a small multiples of heatmaps to see if there is any correlation between two of the weather variables and the number of accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(coll_weather).mark_rect().encode(\n",
    "#     alt.X(alt.repeat(\"column\"), type='ordinal', bin=True),\n",
    "#     alt.Y(alt.repeat(\"row\"), type='ordinal', bin=True),\n",
    "#     color='average(collisions):Q'\n",
    "# ).properties(\n",
    "#     width=150,\n",
    "#     height=150\n",
    "# ).repeat(\n",
    "#     row=['temp', 'windspeed', 'humidity', 'cloudcover', 'visibility'],\n",
    "#     column=['temp', 'windspeed', 'humidity', 'cloudcover', 'visibility']\n",
    "# ).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this visualization we still do not see significant correlation of weather coditions and accidents. We find two more problems: in a lot of the heatmaps there is too many white cells because we do not have any data for that combination of variables, and the other problem is that the heatmaps only lets compare two variables with the number of accidents at a time, which results in having to plot a lot of heatmaps to compare all the variables.\n",
    "\n",
    "We do not see that we can obtain significant results with heatmaps so we will change the type of chart again. We will try to use a scatter plot to see if we can see any correlation between the variables and the number of collisions. Apart of the two axis, we will use the size, color and shape of the points to encode more variables. Since color and shape are better for categorical variables, we will encode the weather conditions and year in those respectively. Furthermore, we will encode the number of collisions in tye y-axis because is the main variable we want to compare with the others. However, on the x-axis and size of the points, we will try multiple combinations of variables to see if we can see any correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(coll_weather).mark_point(opacity = 0.5, filled = True).encode(\n",
    "#     alt.X('temp:Q', title='Average Daily Temperature (C)', scale=alt.Scale(domain=[15, 31])),\n",
    "#     #alt.X('windspeed:Q', title='Avearge Daily Windspeed (km/h)', scale=alt.Scale(domain=[8, 45])),\n",
    "#     #alt.X('humidity:Q', title='Average Daily Humidity (%)', scale=alt.Scale(domain=[40, 95])),\n",
    "#     alt.Size('visibility:Q', title='Average Daily Visibility (km)', scale=alt.Scale(domain=[11, 16])),\n",
    "#     #alt.Size('precip:Q', title='Average Daily Precipitation (mm)', scale=alt.Scale(domain=[0, 50])),\n",
    "#     alt.Color('conditions', title='Weather Conditions'),\n",
    "#     alt.Y('collisions', title='Number of Collisions', scale=alt.Scale(domain=[150, 900])),\n",
    "#     alt.Shape('year:N', title='Year')\n",
    "# ).properties(\n",
    "#     width=600,\n",
    "#     height=400\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the combinations gives us enogh evidence to conclude that there is any correlation between the variables and the number of collisions. However, since we see that the number of collisions is higher in 2020 than in 2018, we will try to juxtapose the scatter plots of both years to see if get any insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart for 2018\n",
    "chart_2018 = alt.Chart(coll_weather_2018).mark_point(opacity=0.5, filled=True).encode(\n",
    "    alt.X('temp:Q', title='Average Daily Temperature (C)', scale=alt.Scale(domain=[15, 31])),\n",
    "    alt.Size('visibility:Q', title='Average Daily Visibility (km)', scale=alt.Scale(domain=[11, 16])),\n",
    "    alt.Color('conditions', title='Weather Conditions', scale=alt.Scale(scheme='set2')),\n",
    "    alt.Y('collisions', title='Number of Collisions', scale=alt.Scale(domain=[350, 900])),\n",
    ").properties(\n",
    "    title='Collisions and Weather Conditions in 2018',\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Chart for 2020\n",
    "chart_2020 = alt.Chart(coll_weather_2020).mark_point(opacity=0.5, filled=True).encode(\n",
    "    alt.X('temp:Q', title='Average Daily Temperature (C)', scale=alt.Scale(domain=[15, 31])),\n",
    "    alt.Size('visibility:Q', title='Average Daily Visibility (km)', scale=alt.Scale(domain=[11, 16])),\n",
    "    alt.Color('conditions', title='Weather Conditions', scale=alt.Scale(scheme='set2')),\n",
    "    alt.Y('collisions', title='Number of Collisions', scale=alt.Scale(domain=[150, 500])),\n",
    ").properties(\n",
    "    title='Collisions and Weather Conditions in 2020',\n",
    "    width=600,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Display the charts side by side\n",
    "# chart_2018 | chart_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite not getting enough insides, we see that there might be a correlation between the number of collisions and weather conditions. However, to compare these two, this scatterplot is not the best option. We will try to use a bar chart instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(coll_weather).mark_bar().encode(\n",
    "#     y=alt.Y('conditions:N', sort='-x', title='Weather Conditions'),\n",
    "#     x=alt.X('collisions:Q', axis=alt.Axis(title='Number of Collisions'))\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the total number of collisions by weather conditions we see a pattern that we did not see in the previous graphs. However, since we are counting the number of collisions with each of the weather conditions, and there are not the same days with each of the conditions, we cannot conclude anything. To improve this visualization we will get the average number of collisions per day with each of the weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(coll_weather).mark_bar().encode(\n",
    "#     y=alt.Y('conditions:N', sort='-x', title='Weather Conditions'),\n",
    "#     x=alt.X('average_collisions_condition:Q', axis=alt.Axis(title='Average Number of Collisions per Day')),\n",
    "# ).transform_aggregate(\n",
    "#     total_days_condition='count()',\n",
    "#     total_collisions_condiditon='sum(collisions)',\n",
    "#     groupby=['conditions']\n",
    "# ).transform_calculate(\n",
    "#     average_collisions_condition='datum.total_collisions_condiditon / datum.total_days_condition'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are starting to get interesting results. We see that the average number of collisions is higher with worse weather conditions, and lowers with better weather conditions. However, we still cannot conclude anything because bar charts are not the best option to compare averages since we do not see the variance and the distribution of the data. To improve this visualization and see the distribution of the data we will use a violin plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(coll_weather, width=100).transform_density(\n",
    "#     'collisions',\n",
    "#     as_=['collisions', 'density'],\n",
    "#     extent=[0, 1200],\n",
    "#     groupby=['conditions']\n",
    "# ).mark_area(orient='horizontal').encode(\n",
    "#     alt.X('density:Q')\n",
    "#         .stack('center')\n",
    "#         .impute(None)\n",
    "#         .title(None)\n",
    "#         .axis(labels=False, values=[0], grid=False, ticks=True),\n",
    "#     alt.Y('collisions:Q'),\n",
    "#     alt.Color('conditions:N', scale=alt.Scale(scheme='set2')),\n",
    "#     alt.Column('conditions:N')\n",
    "#         .spacing(0)\n",
    "#         .header(titleOrient='bottom', labelOrient='bottom', labelPadding=0)\n",
    "# ).configure_view(\n",
    "#     stroke=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this visualization we still see that as worse weather conditions, more collisions. Dispite that, we still cannot see the median and quartiles of the data, so we will superpose a boxplot to the violin plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_right = (\n",
    "    alt.Chart(coll_weather, width=100)\n",
    "    .transform_density(\n",
    "        \"collisions\",\n",
    "        as_=[\"collisions\", \"density\"],\n",
    "        extent=[0, 1200],\n",
    "        groupby=[\"conditions\"]\n",
    "    )\n",
    "    .mark_area(orient=\"horizontal\")\n",
    "    .encode(\n",
    "        alt.X(\"density:Q\")\n",
    "            .impute(None)\n",
    "            .title(None)\n",
    "            .axis(labels=False, grid=False, ticks=True),\n",
    "        alt.Y(\"collisions:Q\"),\n",
    "        alt.Color(\"conditions:N\", scale=alt.Scale(scheme='set2'))\n",
    "    )\n",
    ")\n",
    "\n",
    "violin_left = (\n",
    "    violin_right\n",
    "    .copy()\n",
    "    .transform_calculate(density=\"-datum.density\")\n",
    ")\n",
    "\n",
    "boxplot = (\n",
    "    alt.Chart(coll_weather, width=100)\n",
    "    .mark_boxplot(outliers=False, size=10, extent=20)\n",
    "    .encode(y=\"collisions:Q\", color=alt.value(\"black\"))\n",
    ")\n",
    "\n",
    "chart = (\n",
    "    alt.layer(violin_left, violin_right,boxplot)\n",
    "    .facet(alt.Column(\"conditions:N\"))\n",
    "    .configure_view(stroke=None)\n",
    ")\n",
    "# chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs is getting better, however, we see in each weather condition violin two bulks of data, which correspon to the two years. We have seen in previous graphs that there is a significant difference between the number of collisions in 2018 and 2020, so we will try to separate the data by year to see each distribution separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 80\n",
    "\n",
    "boxplot = alt.Chart().mark_boxplot(color='black').encode(\n",
    "    alt.Y(f'collisions:Q')\n",
    ").properties(width=width)\n",
    "\n",
    "violin = alt.Chart().transform_density(\n",
    "    'collisions',\n",
    "    as_=['collisions', 'density'],\n",
    "    extent=[0, 1000],\n",
    "    groupby=['conditions']\n",
    ").mark_area(orient='horizontal').encode(\n",
    "    y='collisions:Q',\n",
    "    color=alt.Color('conditions:N', legend=None, scale=alt.Scale(scheme='set2')),\n",
    "    x=alt.X(\n",
    "        'density:Q',\n",
    "        stack='center',\n",
    "        impute=None,\n",
    "        title=None,\n",
    "        scale=alt.Scale(nice=False, zero=False),\n",
    "        axis=alt.Axis(labels=False, values=[0], grid=False, ticks=True),\n",
    "    ),\n",
    ").properties(\n",
    "    width=width,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "facet = lambda coll_weather, title: alt.layer(violin, boxplot, data=coll_weather).facet(column='conditions:N').resolve_scale(x=alt.ResolveMode(\"independent\")).properties(title=alt.TitleParams(text=title, anchor=\"middle\", align=\"center\"))\n",
    "\n",
    "# alt.hconcat(facet(coll_weather_2018, \"Summer 2018\"),facet(coll_weather_2020, \"Sumer 2020\")).configure_facet(\n",
    "#     spacing=0,\n",
    "# ).configure_header(\n",
    "#     titleOrient='bottom',\n",
    "#     labelOrient='bottom'\n",
    "# ).configure_view(\n",
    "#     stroke=None\n",
    "# ).properties(\n",
    "#     title='Collisions and Weather Conditions in 2018 and 2020',\n",
    "# ).configure_title(\n",
    "#       anchor='middle', offset=25, fontSize=18, fontStyle='normal', fontWeight='normal'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have finally achieved the final version of the graph. This visualization facilitates the identification of the distribution of the number of collisions by weather conditions. We see that, in 2018, the median of the number of collisions is higher with rain conditions but with the other weather conditions there is not a significant difference between the number of collisions. In 2020 we do not see enough evidence to conclude that a type of weather condition is more likely to cause an accident. These probably happens because in 2020 there was a lockdown and people were not driving as much as in 2018 so there were less cars on the road and the weather conditions did not affect as much as in 2018. Furthermore, we see that the distribution of the data is wider in 2020 than in 2018, which means that there is more variance in the number of collisions.\n",
    "\n",
    "We have ended up choosing this visualization despite not having the quantitative wheather variables such as temperature or precipitation because the weather conditions take into account all these variables into a categorical one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is there a correlation between weather conditions and accidents?*\n",
    "\n",
    "In chart C5 you see a violin plot with the distribution of the number of accidents per day with each of the weather conditions and year. We use a different color for each year to compare them. By looking at the median of the boxplot, you can see that in 2018 this median (and the overall distribution of collisions) is higher with rain conditions but with the other weather conditions there is not a significant difference between the number of collisions. In 2020 we do not see enough evidence to conclude that a type of weather condition is more likely to cause an accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus chart\n",
    "\n",
    "gaussian_jitter = alt.Chart(coll_weather, title='Normally distributed jitter').mark_circle(size=20).encode(\n",
    "    y=\"conditions:N\",\n",
    "    x=\"collisions:Q\",\n",
    "    yOffset=\"jitter:Q\",\n",
    "    color=alt.Color('conditions:N').legend(None),\n",
    "    shape=alt.Shape('year:N')\n",
    ").transform_calculate(\n",
    "    # Generate Gaussian jitter with a Box-Muller transform\n",
    "    jitter=\"sqrt(-2*log(random()))*cos(2*PI*random())\"\n",
    ").properties(\n",
    "    width=300, height=200\n",
    ")\n",
    "\n",
    "uniform_jitter = gaussian_jitter.transform_calculate(\n",
    "    # Generate uniform jitter\n",
    "    jitter='random()'\n",
    ").encode(\n",
    "    alt.Y('conditions:N').axis(None)\n",
    ").properties(\n",
    "    title='Uniformly distributed jitter',\n",
    "    width=300, height=200,\n",
    ")\n",
    "\n",
    "# (gaussian_jitter | uniform_jitter).resolve_scale(yOffset='independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the annual fatality count in accidents in New York, and how does that total break down by user type, including pedestrians, cyclists, and motorists?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In consideration of the available data, we have found it beneficial to analyze the information on the number of fatalities in traffic accidents in New York over the years at our disposal. In this way, we aim to determine the annual count of fatal accidents and the respective distribution of these fatalities among pedestrians, cyclists, and motorists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadly_accidents = collisions[['CRASH_DATE', 'TOTAL_KILLED', 'PEDESTRIANS_KILLED', 'CYCLIST_KILLED', 'MOTORIST_KILLED']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we verify that the total number of deaths is equivalent to the sum of deaths across different user types to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows eliminated: 5\n"
     ]
    }
   ],
   "source": [
    "deadly_accidents = deadly_accidents[deadly_accidents['TOTAL_KILLED'] == deadly_accidents['PEDESTRIANS_KILLED'] + \\\n",
    "                                                                        deadly_accidents['CYCLIST_KILLED'] + \\\n",
    "                                                                        deadly_accidents['MOTORIST_KILLED']]\n",
    "\n",
    "print(f'Rows eliminated: {len(collisions) - len(deadly_accidents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>PEDESTRIANS_KILLED</th>\n",
       "      <th>CYCLIST_KILLED</th>\n",
       "      <th>MOTORIST_KILLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  PEDESTRIANS_KILLED  CYCLIST_KILLED  MOTORIST_KILLED\n",
       "0  2018                  40               5               43\n",
       "1  2020                  38              15               61"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deadly_accidents = deadly_accidents.drop(columns=['TOTAL_KILLED'])\n",
    "deadly_accidents['CRASH_DATE'] = pd.to_datetime(deadly_accidents['CRASH_DATE'])\n",
    "deadly_accidents['year'] = deadly_accidents['CRASH_DATE'].dt.year\n",
    "deadly_accidents = deadly_accidents.groupby('year').sum(['PEDESTRIANS_KILLED', 'CYCLIST_KILLED', 'MOTORIST_KILLED']).reset_index()\n",
    "deadly_accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>killed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>motorist</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>pedestrians</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>cyclist</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>motorist</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>pedestrians</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>cyclist</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         type  killed\n",
       "0  2020     motorist      61\n",
       "1  2020  pedestrians      38\n",
       "2  2020      cyclist      15\n",
       "3  2018     motorist      43\n",
       "4  2018  pedestrians      40\n",
       "5  2018      cyclist       5"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deadly_accidents_melted = deadly_accidents.melt('year', var_name='type', value_name='killed')\n",
    "deadly_accidents_melted['type'] = deadly_accidents_melted['type'].apply(lambda x: x.split('_')[0].lower())\n",
    "deadly_accidents_melted = deadly_accidents_melted.sort_values(by=['year', 'killed'], ascending=False).reset_index(drop=True)\n",
    "deadly_accidents_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider that a bar chart can encode the information we need optimally. We envision a bar chart where the number of deaths is on the y-axis, and the year is on the x-axis. We find it appropriate to have the year on the x-axis because this follows the standard practice in data visualization and makes it easier for viewers to interpret the chart. We will use a categorical palette to differentiate effectively between the various categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortal_collisions = alt.Chart(deadly_accidents_melted).mark_bar().encode(\n",
    "    x=alt.X('year:O', title='Year'),\n",
    "    y=alt.Y('sum(killed):Q', title='Number of deaths'),\n",
    "    color=alt.Color('type:N', scale=alt.Scale(scheme='set2'), legend=alt.Legend(title='Type of user')),\n",
    "    order=alt.Order('type', sort='ascending'),\n",
    ")\n",
    "\n",
    "# mortal_collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that comparing the number of deaths each year is feasible, but comparing the number of deaths by type is not as accurate, also within the same year. Therefore, we find it beneficial to add labels indicating the quantity of deaths per user type. This addition will facilitate efficient comparisons between different user categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the position of the text labels manually\n",
    "deadly_accidents_melted['position'] = [61+15, 61+38+15, 15, 43+5, 43+40+5, 5]\n",
    "\n",
    "number_of_deaths = alt.Chart(deadly_accidents_melted).mark_text(color='white', dy=7).encode(\n",
    "    x=alt.X('year:O', title='Year'),\n",
    "    y=alt.Y('position:Q', title='Number of deaths'),\n",
    "    text=alt.Text('killed:Q', format='.0f')\n",
    ")\n",
    "\n",
    "# (mortal_collisions + number_of_deaths).properties(\n",
    "#      title='Number of deaths by type of user and year'\n",
    "# ).configure_title(\n",
    "#   anchor='middle', offset=25, fontSize=16, fontStyle='normal', fontWeight='normal'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers to Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are accidents more frequent during weekdays or weekends? Is there any difference between before COVID-19 and after?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the top-left chart, orange bars represent data from the year 2018, while blue bars represent data from 2020 (before and after COVID, respectively). Analyzing the length of the bars reveals a consistent trend: on all days of the week, the total number of accidents occurring on each day is considerably higher (more than double in all cases) before COVID compared to after.\n",
    "\n",
    "Furthermore, in the right slope chart, where colors correspond to those in the paired bar chart, a decreasing trend is evident in the number of accidents on weekdays versus weekends. Weekends consistently exhibit a lower average number of accidents both before and after COVID. Notably, this difference intensifies before COVID, indicating a more pronounced contrast. However, in 2020, the difference is not as significant.\n",
    "\n",
    "From this graph, we can infer that the number of traffic accidents has decreased post-COVID, and this reduction in accidents on weekends has followed a similar trend, with a slight decrease in the decline. One possible explanation is the reduced use of both public and private transportation on weekends due to decreased overall activity (work, school, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any type of vehicle more prone to participate in accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the middle-right chart, we can observe the number of accidents involving different types of vehicles in both 2018 and 2020 (from June to September). In this case, we cannot directly answer the question about which vehicles are more prone to accidents, as it would require knowledge of the number of vehicles of each type in New York (or circulating in New York). Quantifying this is a challenging task since, for example, although we see that Sedans have the highest number of accidents, there are likely also many more Sedan-type cars on the roads in New York. The same may be true for SUVs. By examining the length of the bars or directly looking at the numbers at the end of each bar, we can note that sedans and SUVs are the vehicle types most frequently involved in accidents, overshadowing other vehicles such as taxis, pickups, bicycles, etc.\n",
    "\n",
    "Despite the difficulty in quantifying the total number of each vehicle type, what we can conclude is that Sedans and SUVs mentioned earlier contribute to a significant percentage of accidents in New York. By observing that the bars are well to the right of the red bar (mean accidents), it's evident that these values are well above the average accidents per vehicle. It's also noteworthy that taxis, although likely fewer in number, still have a notable frequency of accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At what time of the day are accidents more common?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the middle-left, you can see a line chart with the average accidents per hour along the summers of 2018 and 2020. A different color for each year has been used as well as the line thickness to encode the killed people. Regarding the question asked about what time of the day are accidents more common, a clear trend emerges: higher collision rates during the day and lower rates during the night. This pattern aligns with the increased presence of cars on the road during daylight hours and decreased activity during nighttime. Further we can distinguish different patterns between morning, afternoon, and evening periods. Mornings exhibit fewer collisions, likely attributed to work-related activities, whereas afternoons register higher incidents, potentially linked to leisure activities and transporting children to extracurricular activities. Evenings witness a decline in collisions as people conclude their activities and are back home.\n",
    "\n",
    "Furthermore, by looking at the line thickness we can see that the deathliest hours are at 20:00 and 04:00 in 2018, and between 19:00 and 00:00, as well as at 04:00 in 2020. The deaths in the late night coincide with the times when people are returning home after socializing, often under the influence of alcohol, which make the accidents more dangerous. However, beeing able to see that is more difficult because, one of the drawbacks of this visualization is that the line thickness is not easy to compare. Another criticism is that the error bars make the patterns a difficult to read. Dispite that it is important to keep them in the visualization because they show the variance of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any areas with a larger number of accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the map in the top-right chart, we can observe areas with a higher concentration of accidents per square kilometer. This is evident by examining the intensity of the blue color, where darker shades of blue indicate a higher number of accidents per kmÂ². Knowing this, we can see that areas with the highest accident ratios are located in the southern part of Manhattan, featuring zones with a significant number of accidents. It's also noteworthy that there are dark blue areas in the center of Brooklyn, indicating a high number of accidents. The same pattern occurs in some southwestern parts of the Bronx and a specific postal code area in Queens, situated in the northwest. In Staten Island, the color intensity is very low, indicating a low number of accidents per kmÂ² throughout the borough.\n",
    "\n",
    "In the bar chart to the right of the map, we can interpret, based on the length of the bars, that Manhattan has by far the highest number of accidents per kmÂ², which aligns with our observation on the map. Following Manhattan, there are relatively high accident rates in Brooklyn, the Bronx, Queens, and, lastly, as observed earlier, Staten Island, with significantly fewer accidents compared to the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a correlation between weather conditions and accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bottom, we can see two violin plots juxtaposed, one for each year (2018 and 2020). The x-axis represents the weather conditions, and the y-axis represents the number of accidents per day. The width of the violin shows the distribution of the data, and the boxplot inside the violin shows the median and quartiles of the data.\n",
    "\n",
    "The first thing we can observe is that the distribution of the data is wider in 2020 than in 2018, which means that there is more variance in the number of collisions. Furthermore, we see that, in 2018, the median of the number of collisions is higher with rain conditions but with the other weather conditions there is not a significant difference between the number of collisions. In 2020 we do not see enough evidence to conclude that a type of weather condition is more likely to cause an accident. These probably happens because in 2020 there was a lockdown and people were not driving as much as in 2018 so there were less cars on the road and the weather conditions did not affect as much as in 2018. In general we conclude that despite having some evidence, it is not enough to conclude that there is a correlation between weather conditions and accidents. If there was, we would be able to see it in the distribution of the data, which would be more concentrated in some weather conditions than in others.\n",
    "\n",
    "The drawbacks of this visualization is that we have not encoded any quantitative variable of the weather conditions because since there are a lot of them, any plot is good enough to be able to see them toghether easily. For that we ended up choosing the weather conditions as a categorical variable which takes into account all the quantitative variables of the weather conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the annual fatality count in accidents in New York, and how does that total break down by user type, including pedestrians, cyclists, and motorists?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bottom-left chart, we can observe the number of fatalities in accidents depending on the year (summer). Looking at the length of the first bar, we can see that in 2018 (summer), there were 88 fatal accidents, and in 2020, there were 114, an increase of 26. We notice that fatal accidents constitute a very small percentage of the total accidents, indicating that typically, there are few accidents resulting in fatalities. This is surprising, as shown in the top-left chart, where there are many more accidents in 2018 than in 2020, yet in 2020, they are more lethal.\n",
    "\n",
    "Examining the numbers within each color of the bar chart allows us to compare the number of fatalities each year based on the type of user. We observe that the most significant difference is in the number of motorist deaths, which has increased by 18."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
