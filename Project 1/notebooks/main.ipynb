{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collisions in NY City\n",
    " Carlos Arbonés & Benet Ramió"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We acquired the dataset from the [Motor Vehicle Collisions](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95) source. Prior to obtaining it, we specifically filtered and downloaded the records corresponding to the periods of June to September in both 2018 and 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial dataset contains 115740 rows and 30 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the preprocessing process, we meticulously reviewed every column, focusing on aspects such as data types, the presence of null values, and potential clustering patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'Crash Date' column, we have maintained the data type as text, and it's important to note that **no null values** were found. The data within this column also appears to be in a **consistent format**. To enhance data organization and facilitate further analysis, we have **sorted** rows by 'Crash Date'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 'Crash Time' column, we've observed that **no null values** are present. Notably, we noticed specific hours, such as 00:00 and 13:00, a significant number of accidents occur. Exact hours, like 15:20 or 6:45, are more frequent than minutes, for instance, 19 or 23. This suggests that officers might commonly make **typographical errors** when recording minute values, which we have taken into account during the preprocessing process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Borough' column contains a limited set of distinct values, namely, **BRONX, BROOKLYN, MANHATTAN, QUEENS, STATEN ISLAND**, and blank. Notably, there are a significant number of records where the 'Borough' value is **blank**, with a total of **40,671** occurrences. We do not eliminate these rows, as they can be used for counting and other applications. We also explored the option of imputing values using the GeoPandas library; however, due to the high cost and the prevalence of missing values, it would take a considerable amount of time. Therefore, we have taken into account the existence of blank entries for later consideration in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have transformed the data type of the 'ZIP Code' column to number for improved consistency and analysis.\n",
    "\n",
    "We've observed that there are 208 distinct zip codes within the dataset. It's important to note that a even though having too many zip codes, they can be extracted to the borough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude, Longitude and Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data preprocessing phase, we took several steps to enhance the quality and consistency of the 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "We first converted the data type of 'Latitude' and 'Longitude' to number. We also made the decision to remove the 'Location' column since the necessary information is now adequately represented in the 'Latitude' and 'Longitude' columns. It's important to highlight that there are a total of 7,667 blank values in these columns.\n",
    "\n",
    "During the data inspection, we identified atypical and impossible values, such as a longitude of -201. These outliers were associated with the location \"QUEENSBORO BRIDGE UPPER BROADWAY\", and after verifying the correct longitude, we adjusted these values to -73.954224. Similar outlier corrections were made for the \"NASSAU EXPRESSWAY\" location, where the previous value of -32 was corrected to -73.7813672, and for the \"WEST SHORE EXPRESSWAY\", where the previous value of -74.7 was corrected to -74.1864671. Finally, rows that had both 'Latitude' and 'Longitude' values equal to 0 were modified to contain blank text values, promoting uniformity and clarity in the dataset.\n",
    "\n",
    "These preprocessing actions have been taken to ensure that the 'Latitude' and 'Longitude' data are accurate, free from anomalies, and suitable for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ON STREET NAME, CROSS STREET NAME and OFF STREET NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of our data preprocessing, we have opted to remove the 'On Street Name,' 'Cross Street Name,' and 'Off Street Name' columns from the dataset. This decision is influenced by several key factors. Firstly, these columns contained a significant number of blank values, with 'On Street Name' having approximately 28,000 blanks, 'Cross Street Name' over 57,000 blanks, and 'Off Street Name' about 80,000 blanks. The prevalence of missing data in these columns significantly affected the overall data quality.\n",
    "\n",
    "Furthermore, the information contained within these columns was found to be redundant, and the extensive variety of street names made it challenging to derive meaningful insights or create compelling visualizations based on these columns. To fulfill the need for location-related information, we have chosen to rely on the 'Latitude' and 'Longitude' columns, which provide more structured and comprehensive geographic data. This not only reduces redundancy but also enhances data clarity and usability for our visualization project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INJURED AND KILLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have changed the datatype of all the injured and killed columns to number as well as changed the column names to shorter and more informative ones.\n",
    "The old column names and their corresponding new names are as follows:\n",
    "\n",
    "- NUMBER OF PERSONS INJURED -> TOTAL_INJURED\n",
    "- NUMBER OF PERSONS KILLED -> TOTAL_KILLED\n",
    "- NUMBER OF PEDASTRIANS INJURED -> PEDASTRIANS_INJURED\n",
    "- NUMBER OF PEDASTRIANS KILLED -> PEDASTRIANS_KILLED\n",
    "- NUMBER OF CYCLISTS INJURED -> CYCLISTS_INJURED\n",
    "- NUMBER OF CYCLISTS KILLED -> CYCLISTS_KILLED\n",
    "- NUMBER OF MOTORISTS INJURED -> MOTORISTS_INJURED\n",
    "- NUMBER OF MOTORISTS KILLED -> MOTORISTS_KILLED\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLISION_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have removed this column since it is not needed for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE TYPE CODE 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both 'VEHICLE TYPE CODE 1' and 'VEHICLE TYPE CODE 2,' a comprehensive data standardization process was undertaken. Initially, we applied clustering techniques using the Nearest Neighbor Method and Key Collision Method to harmonize and unify vehicle type names. These automated methods aided in resolving many inconsistencies caused by human errors.\n",
    "\n",
    "Recognizing that the automated clustering did not catch all errors, we conducted a meticulous manual review of vehicle type names. In cases where specific vehicles were inaccurately described, we updated their names. For instance, we found entries like 'GLP050VXEV,' which, upon internet research, was identified as a forklift model, so we modified it accordingly. Similar manual refinements were applied to various other vehicle types to improve accuracy and consistency.\n",
    "\n",
    "Additionally, we adopted a generalization approach to simplify overly specific vehicle types. For example, entities like 'FedEx,' 'UPS,' 'mail' and others were categorized under 'delivery' to reduce the number of distinct vehicle classes.\n",
    "\n",
    "To further enhance data consistency, vehicle types with fewer than ten collisions were grouped under the 'Others' category to streamline the dataset and reduce the number of unique names.\n",
    "\n",
    "It is remarkably that before these transformations, 'VEHICLE TYPE CODE 1' had 361 different names, and 'VEHICLE TYPE CODE 2' had 373 and, after, there are 42 and 44 respectivly. These preprocessing steps aimed to standardize and simplify the vehicle type data, making it more manageable and coherent for our analysis and visualization efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VEHICLE TYPE CODE 3, 4 & 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that the majority of accidents typically involve two vehicles, the 'VEHICLE TYPE CODE 3,' 'VEHICLE TYPE CODE 4,' and 'VEHICLE TYPE CODE 5' columns contained a significant number of blank values. Specifically, 'VEHICLE TYPE CODE 3' had 107,095 blanks, 'VEHICLE TYPE CODE 4' had 113,658 blanks, and 'VEHICLE TYPE CODE 5' had 115,154 blanks. These observations indicate that the vast majority of records in these columns did not contain meaningful data.\n",
    "\n",
    "To streamline the dataset and focus on more relevant and informative columns, we have made the decision to remove these three columns. The absence of data in these columns, coupled with their limited relevance for our visualizations, makes their removal a practical and efficient choice in our data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTING_FACTOR_VEHICLE1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the types of charts we want to create, we found it beneficial to add more attributes to the dataset, particularly those related to the date. In this case, we decided to combine the 'CRASH_DATE' and 'CRASH_TIME' columns into a single column containing the data in a format suitable for Altair. We created a new column named 'CRASH_DATETIME' in the format '%m/%d/%Y %H:%M'. We also added another column, 'DAY_WEEK,' that indicates the day of the week when the accident occurred (e.g., Monday, ...). Additionally, we introduced a column named 'TYPE_DAY' containing values 'Weekend' and 'Weekday' based on whether the accidents happened on the weekend or during the week, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = pd.read_csv(\"../data/preprocessed-colisions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions['CRASH_DATETIME'] = pd.to_datetime(collisions['CRASH_DATE'] + ' ' + collisions['CRASH_TIME'], format='%m/%d/%Y %H:%M')\n",
    "collisions = collisions.drop(columns=['CRASH_DATE', 'CRASH_TIME'])\n",
    "collisions['DAY_WEEK'] = collisions['CRASH_DATETIME'].dt.day_name()\n",
    "collisions['TYPE_DAY'] = collisions['DAY_WEEK'].apply(lambda day: 'Weekend' if day in ['Saturday', 'Sunday'] else 'Weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.to_csv(\"../data/preprocessed-collisions-final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the preprocessing, the dataset has 115740 rows and 22 columns\n"
     ]
    }
   ],
   "source": [
    "print(f'After the preprocessing, the dataset has {len(collisions)} rows and {len(collisions.columns)} columns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
