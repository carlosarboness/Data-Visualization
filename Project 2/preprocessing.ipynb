{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing üõ†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors**: Carlos Arbon√©s & Benet Rami√≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin, make sure you have a folder named **data** within this repository containing the following files for the code to run correctly:\n",
    "\n",
    "- *weather2018.csv*\n",
    "- *preprocessed-collisions.csv*\n",
    "- *preprocessed-collisions-2.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collisions dataset üí•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the preprocessing conducted in the previous exercise is suitable for this project. Therefore, the only adjustment required is to filter and retain only the rows corresponding to AMBULANCES, TAXIS, and FIRE TRUCKS, as specified in the project description. Additionally, we have chosen to include only the samples from the year 2018 and have removed unnecessary columns for the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = pd.read_csv('data/preprocessed-collisions.csv') \n",
    "collisions['CRASH_DATETIME'] = pd.to_datetime(collisions['CRASH_DATE'] + ' ' + collisions['CRASH_TIME'], format='%m/%d/%Y %H:%M')\n",
    "collisions = collisions.drop(columns=['CRASH_DATE', 'CRASH_TIME', 'CONTRIBUTING_FACTOR_VEHICLE2', 'VEHICLE_TYPE_CODE2'])\n",
    "collisions = collisions[collisions['CRASH_DATETIME'].dt.year == 2018] # Only 2018 data\n",
    "collisions = collisions[collisions['VEHICLE_TYPE_CODE1'].isin(['Taxi', 'Ambulance', 'Fire truck'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4093, 15)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOROUGH                         1385\n",
       "ZIP_CODE                        1385\n",
       "LATITUDE                         294\n",
       "LONGITUDE                        294\n",
       "TOTAL_INJURED                      1\n",
       "TOTAL_KILLED                       1\n",
       "PEDESTRIANS_INJURED                0\n",
       "PEDESTRIANS_KILLED                 0\n",
       "CYCLIST_INJURED                    0\n",
       "CYCLIST_KILLED                     0\n",
       "MOTORIST_INJURED                   0\n",
       "MOTORIST_KILLED                    0\n",
       "CONTRIBUTING_FACTOR_VEHICLE1       0\n",
       "VEHICLE_TYPE_CODE1                 0\n",
       "CRASH_DATETIME                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 1385 missing values in the 'BOROUGH' and 'ZIP_CODE' columns and only 294 missing values in the coordinates, we will impute the values where we have LATITUDE and LONGITUDE but are missing 'BOROUGH' or 'ZIP_CODE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_location_info(latitude, longitude):\n",
    "    geolocator = Nominatim(user_agent=\"my_geocoder\") # initialize geolocator\n",
    "    location = geolocator.reverse((latitude, longitude), language=\"en\") # reverse geocoding\n",
    "    borough = location.raw['address']['suburb'].upper() if 'suburb' in location.raw['address'] else location.raw['address']['city'].upper()\n",
    "    zip_code = location.raw['address']['postcode'] if 'postcode' in location.raw['address'] else None\n",
    "\n",
    "    return borough, zip_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_borough_or_zip = (collisions['BOROUGH'].isna() | collisions['ZIP_CODE'].isna()) # filter for rows with missing borough or zip code\n",
    "has_lat_long = (collisions['LATITUDE'].notna() & collisions['LONGITUDE'].notna()) # filter for rows with latitude and longitude\n",
    "\n",
    "missing_locations = collisions[no_borough_or_zip & has_lat_long] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code takes about 10 minutes to execute; we use the previously defined function to impute values for BOROUGH and ZIP CODE. There's no need to run it again as we have already saved the CSV generated from this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm\n",
    "# for row in tqdm.tqdm(missing_locations.itertuples()):\n",
    "#     borough, zip_code = get_location_info(row.LATITUDE, row.LONGITUDE)\n",
    "#     collisions.loc[row.Index, 'BOROUGH'] = borough\n",
    "#     collisions.loc[row.Index, 'ZIP_CODE'] = zip_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOROUGH\n",
       "MANHATTAN        1665\n",
       "BROOKLYN          402\n",
       "QUEENS            331\n",
       "BRONX             306\n",
       "STATEN ISLAND       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions['BOROUGH'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We corrected some inconsistencies by changing neighborhood names from 'THE BRONX' to 'BRONX' and from 'QUEENS COUNTY' to 'QUEENS'. Additionally, we removed the rows that had 'KINGS COUNTY' as the neighborhood since it refers to a neighborhood in California. We assume that the data for those rows is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.loc[collisions['BOROUGH'] == 'THE BRONX', 'BOROUGH'] = 'BRONX' # standardize borough names\n",
    "collisions.loc[collisions['BOROUGH'] == 'QUEENS COUNTY', 'BOROUGH'] = 'QUEENS' # standardize borough names\n",
    "collisions = collisions[collisions['BOROUGH'] != 'KINGS COUNTY'].reset_index(drop=True) # remove rows with borough 'KINGS COUNTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOROUGH\n",
       "MANHATTAN        1665\n",
       "BROOKLYN          402\n",
       "QUEENS            331\n",
       "BRONX             306\n",
       "STATEN ISLAND       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions['BOROUGH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOROUGH                         0.338383\n",
       "ZIP_CODE                        0.338383\n",
       "LATITUDE                        0.071830\n",
       "LONGITUDE                       0.071830\n",
       "TOTAL_INJURED                   0.000244\n",
       "TOTAL_KILLED                    0.000244\n",
       "PEDESTRIANS_INJURED             0.000000\n",
       "PEDESTRIANS_KILLED              0.000000\n",
       "CYCLIST_INJURED                 0.000000\n",
       "CYCLIST_KILLED                  0.000000\n",
       "MOTORIST_INJURED                0.000000\n",
       "MOTORIST_KILLED                 0.000000\n",
       "CONTRIBUTING_FACTOR_VEHICLE1    0.000000\n",
       "VEHICLE_TYPE_CODE1              0.000000\n",
       "CRASH_DATETIME                  0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentatge of rows with missing values\n",
    "collisions.isna().sum() / collisions.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the maximum percentage of missing values is in Latitude and Longitude, with 7% of the rows containing null values. To maintain data consistency, we have decided to delete the rows that contain null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2551, 15)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions = collisions.dropna().reset_index(drop=True) # drop rows with missing values\n",
    "collisions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collisions.to_csv('data/preprocessed-collisions-2.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = pd.read_csv('data/preprocessed-collisions-2.csv') # read preprocessed collisions data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the \"CRASH_DATETIME\" column, we derive columns that will be very useful and facilitate the study. Specifically, we create the 'MONTH', 'HOUR', 'DAY_WEEK', 'DAY' columns, which refer to the month, hour, day of the week, and day of the month when the accident occurred, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions['CRASH_DATETIME'] = pd.to_datetime(collisions['CRASH_DATETIME'])\n",
    "collisions['MONTH'] = collisions['CRASH_DATETIME'].dt.month_name() \n",
    "collisions['HOUR'] = collisions['CRASH_DATETIME'].dt.hour\n",
    "collisions['DAY_WEEK'] = collisions['CRASH_DATETIME'].dt.day_name()\n",
    "collisions['DAY'] = collisions['CRASH_DATETIME'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We derive the column 'CASUALTIES' as the sum of accidents that have had an impact on people's health, i.e., the sum of 'killed' and 'injured'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions['CASUALTIES'] = collisions['TOTAL_INJURED'] + collisions['TOTAL_KILLED']\n",
    "collisions['CASUALTIES'] = collisions['CASUALTIES'].apply(lambda x: 'Injured or Killed' if x > 0 else 'No Damage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a selection of the columns that are relevant for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = collisions[['BOROUGH', 'ZIP_CODE', 'LATITUDE', 'LONGITUDE', \n",
    "                         'CONTRIBUTING_FACTOR_VEHICLE1', 'VEHICLE_TYPE_CODE1',\n",
    "                         'CRASH_DATETIME', 'MONTH', 'HOUR', 'DAY_WEEK', 'DAY', 'CASUALTIES']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather dataset üå¶Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the weather dataset, which contains only the data we are interested in, i.e., from June to September 2018. Therefore, there is no need to filter by year. Additionally, for our visualizations and to answer the questions, we will only use the 'icon' column, which contains the type of weather condition for each day. No missing values are observed in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime               icon\n",
       "0 2018-06-01               rain\n",
       "1 2018-06-02               rain\n",
       "2 2018-06-03               rain\n",
       "3 2018-06-04               rain\n",
       "4 2018-06-05  partly-cloudy-day"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv('data/weather2018.csv')\n",
    "weather = weather[['datetime', 'icon']] # keep only datetime and icon columns\n",
    "weather['datetime'] = pd.to_datetime(weather['datetime']) # convert datetime column to datetime type\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "icon\n",
       "rain                 75\n",
       "clear-day            23\n",
       "partly-cloudy-day    22\n",
       "cloudy                2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['icon'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['icon'] = weather['icon'].str.replace('-day', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    0\n",
       "icon        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets üîÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the collisions dataset with the weather dataset, so for each accident, we now have information about the weather on that day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3793, 13)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions = collisions.merge(weather, how='left', left_on=collisions['CRASH_DATETIME'].dt.date, right_on=weather['datetime'].dt.date)\n",
    "collisions = collisions.drop(columns=['key_0', 'datetime']) # drop redundant columns\n",
    "collisions.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>CONTRIBUTING_FACTOR_VEHICLE1</th>\n",
       "      <th>VEHICLE_TYPE_CODE1</th>\n",
       "      <th>CRASH_DATETIME</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>DAY_WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>CASUALTIES</th>\n",
       "      <th>icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11218.0</td>\n",
       "      <td>40.644120</td>\n",
       "      <td>-73.98907</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>2018-09-05 23:00:00</td>\n",
       "      <td>September</td>\n",
       "      <td>23</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>No Damage</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10075.0</td>\n",
       "      <td>40.773640</td>\n",
       "      <td>-73.95986</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>2018-08-05 16:45:00</td>\n",
       "      <td>August</td>\n",
       "      <td>16</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>5</td>\n",
       "      <td>Injured or Killed</td>\n",
       "      <td>clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10017.0</td>\n",
       "      <td>40.753480</td>\n",
       "      <td>-73.97879</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>2018-09-18 13:09:00</td>\n",
       "      <td>September</td>\n",
       "      <td>13</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>18</td>\n",
       "      <td>Injured or Killed</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10022.0</td>\n",
       "      <td>40.757214</td>\n",
       "      <td>-73.97183</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>2018-09-24 10:05:00</td>\n",
       "      <td>September</td>\n",
       "      <td>10</td>\n",
       "      <td>Monday</td>\n",
       "      <td>24</td>\n",
       "      <td>No Damage</td>\n",
       "      <td>partly-cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11101.0</td>\n",
       "      <td>40.752937</td>\n",
       "      <td>-73.92204</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>2018-09-30 00:50:00</td>\n",
       "      <td>September</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>30</td>\n",
       "      <td>No Damage</td>\n",
       "      <td>clear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BOROUGH  ZIP_CODE   LATITUDE  LONGITUDE    CONTRIBUTING_FACTOR_VEHICLE1   \n",
       "0   BROOKLYN   11218.0  40.644120  -73.98907                     Unspecified  \\\n",
       "1  MANHATTAN   10075.0  40.773640  -73.95986  Driver Inattention/Distraction   \n",
       "2  MANHATTAN   10017.0  40.753480  -73.97879                     Unspecified   \n",
       "3  MANHATTAN   10022.0  40.757214  -73.97183  Driver Inattention/Distraction   \n",
       "4     QUEENS   11101.0  40.752937  -73.92204  Driver Inattention/Distraction   \n",
       "\n",
       "  VEHICLE_TYPE_CODE1      CRASH_DATETIME      MONTH  HOUR   DAY_WEEK  DAY   \n",
       "0               Taxi 2018-09-05 23:00:00  September    23  Wednesday    5  \\\n",
       "1               Taxi 2018-08-05 16:45:00     August    16     Sunday    5   \n",
       "2               Taxi 2018-09-18 13:09:00  September    13    Tuesday   18   \n",
       "3               Taxi 2018-09-24 10:05:00  September    10     Monday   24   \n",
       "4               Taxi 2018-09-30 00:50:00  September     0     Sunday   30   \n",
       "\n",
       "          CASUALTIES           icon  \n",
       "0          No Damage           rain  \n",
       "1  Injured or Killed          clear  \n",
       "2  Injured or Killed           rain  \n",
       "3          No Damage  partly-cloudy  \n",
       "4          No Damage          clear  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collisions.to_csv('data/preprocessed-collisions-final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
